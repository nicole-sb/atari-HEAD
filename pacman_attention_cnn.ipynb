{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "erdos_projectipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicole-sb/atari-HEAD/blob/main/pacman_attention_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-1Bo3k22lPO"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1NJZ7nNC89hB",
        "outputId": "30d8a878-ee67-4a6e-d13a-fff0ad15da59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h,w = 160,210\n",
        "hidden_size = 256\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "K6cCGswb2uf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Mask(torch.nn.Module):\n",
        "  def  __init__(self):\n",
        "      super().__init__()\n",
        "      self.MLP = torch.nn.Sequential(\n",
        "          torch.nn.Linear(in_features=1000, out_features =  64),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Linear(in_features=65, out_features=h*w*1) #\n",
        "      )\n",
        "      self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "      def forward(self, random_vector, gaze_bias):\n",
        "        #start we have x with shape (1000,)\n",
        "        #apply our fully conncted layer\n",
        "        out = self.MLP(random_vector)\n",
        "        out = out.view() #unflatten\n",
        "        #apply gaze_bias to learned mask\n",
        "        out = out + gaze_bias\n",
        "        #apply sigmoid now to make values go between 0 and 1\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "  def  __init__(self):\n",
        "      super().__init__()\n",
        "      \n",
        "      self.learned_mask = Mask()\n",
        "\n",
        "      self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=100, kernel_size=3, stride=1)\n",
        "      self.relu = torch.nn.ReLU()\n",
        "      self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "      self.flatten = torch.nn.Flatten()\n",
        "      self.MLP = torch.nn.Sequential(\n",
        "          torch.nn.Linear(in_features = 100*h*w, out_features=16),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Linear(in_features=16, out_features=9)\n",
        "      )\n",
        "      self.final_activation = torch.nn.Softmax()\n",
        " \n",
        "  def forward(self, x, random_vector, mask):\n",
        "    \"\"\"This applies our input image with the mask and then runs it\"\"\"\n",
        "\n",
        "    learned_weight_mask = self.learned.mask(random_vector)\n",
        "\n",
        "    \n",
        "    #Apply the mask to the image to get initial input to CNN parts\n",
        "    out = torch.mul(x,mask) #shape (3,h,w)\n",
        "\n",
        "    out = self.conv1(out) #shape (100,h,w)\n",
        "    out = self.relu1(out)\n",
        "    out = self.maxpool1(out)\n",
        "\n",
        "    #apply the f\n",
        "    out = self.flatten(out)\n",
        "\n",
        "    out = self.final_activation(self.MLP(out)) #this will get you probability vector with probs for each class"
      ],
      "metadata": {
        "id": "ZBejCk6g3Z-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 17814\n",
        "images = None #TODO: load_images\n",
        "cnn_model =  CNN()\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "torch.optim.SGD(cnn_model.parameters(),lr=1e-2, momentum=0.9)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for image, gaze_coords, y in training_data:\n",
        "    #every step\n",
        "   \n",
        "\n",
        "    gaze_x, gaze_y = gaze_coords[0], gaze_coords[1]\n",
        "\n",
        "\n",
        "    #make one hot encoded gaze_bias\n",
        "    gaze_bias = torch.zeros((1,h,w))\n",
        "    gaze_bias[:,gaze_y, gaze_x] = 1\n",
        "\n",
        "    #make random vector that will be used to make mask\n",
        "    random_vector = torch.rand(1000)\n",
        "\n",
        "    #zero gradients before calculating gradients of loss with respect to the image\n",
        "    opt_cnn.zero_grad()\n",
        "\n",
        "    #pass image into cnn_model\n",
        "    y_hat = cnn_model(image, gaze_bias)\n",
        "\n",
        "    #calculate loss\n",
        "    loss = loss_func(y_hat, y)\n",
        "\n",
        "    #calculate gradients with backprob\n",
        "    loss.backward()\n",
        "\n",
        "    #step optimizer\n",
        "    opt_cnn.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "pK__zQu52wcN",
        "outputId": "f2cffed3-62e0-433c-b1a5-4e65afa70063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-564ca40e31f1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    num_epochs =\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W0oWaOQSOm0X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}